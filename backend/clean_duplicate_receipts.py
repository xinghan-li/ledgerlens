"""
æ¸…ç†é‡å¤çš„å°ç¥¨

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. æ£€æµ‹æ•°æ®åº“ä¸­çš„é‡å¤å°ç¥¨ï¼ˆåŸºäº file_hash æˆ–å†…å®¹ç›¸ä¼¼åº¦ï¼‰
2. ä¿ç•™æœ€æ—©ä¸Šä¼ çš„é‚£å¼ å°ç¥¨
3. åˆ é™¤é‡å¤çš„å°ç¥¨åŠç›¸å…³æ•°æ®ï¼ˆreceipt_items, receipt_summaries, receipt_processing_runsï¼‰

è¿è¡Œå‰å»ºè®®ï¼š
1. å¤‡ä»½æ•°æ®åº“
2. å…ˆè¿è¡Œ --dry-run æ¨¡å¼æŸ¥çœ‹ä¼šåˆ é™¤å“ªäº›æ•°æ®
3. ç¡®è®¤æ— è¯¯åå†è¿è¡Œå®é™…åˆ é™¤

ä½¿ç”¨æ–¹æ³•ï¼š
    # æŸ¥çœ‹ä¼šåˆ é™¤ä»€ä¹ˆï¼ˆä¸å®é™…åˆ é™¤ï¼‰
    python clean_duplicate_receipts.py --dry-run
    
    # å®é™…åˆ é™¤é‡å¤æ•°æ®
    python clean_duplicate_receipts.py
    
    # åŸºäº user_id æ¸…ç†æŸä¸ªç”¨æˆ·çš„é‡å¤æ•°æ®
    python clean_duplicate_receipts.py --user-id uuid-here
"""
import os
import sys
import io
from dotenv import load_dotenv
from supabase import create_client
from typing import List, Dict, Any
import argparse
from datetime import datetime

# Fix Windows encoding
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# Load environment variables
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("ERROR: Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY in .env")
    sys.exit(1)

# Create Supabase client
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


def find_duplicate_receipts(user_id: str = None) -> List[Dict[str, Any]]:
    """
    æŸ¥æ‰¾é‡å¤çš„å°ç¥¨ï¼ˆåŸºäº file_hashï¼‰
    
    Returns:
        List of duplicate groups, each containing:
        {
            'file_hash': 'hash_value',
            'count': 3,
            'receipts': [
                {'id': 'uuid', 'uploaded_at': 'timestamp', 'current_status': 'success'},
                ...
            ]
        }
    """
    print("\n" + "="*60)
    print("ğŸ” æŸ¥æ‰¾é‡å¤å°ç¥¨...")
    print("="*60)
    
    # Query to find file_hashes that appear more than once
    query = """
    SELECT 
        file_hash,
        COUNT(*) as count,
        ARRAY_AGG(
            json_build_object(
                'id', id,
                'user_id', user_id,
                'uploaded_at', uploaded_at,
                'current_status', current_status,
                'current_stage', current_stage,
                'raw_file_url', raw_file_url
            ) ORDER BY uploaded_at ASC
        ) as receipts
    FROM receipts
    WHERE file_hash IS NOT NULL
    """
    
    if user_id:
        query += f" AND user_id = '{user_id}'"
    
    query += """
    GROUP BY file_hash
    HAVING COUNT(*) > 1
    ORDER BY COUNT(*) DESC, file_hash;
    """
    
    try:
        # Use RPC to execute raw SQL
        result = supabase.rpc('exec_raw_sql', {'sql': query}).execute()
        duplicates = result.data if result.data else []
        
        if not duplicates:
            # Try alternative method: query all receipts and find duplicates in Python
            print("âš ï¸  RPC method failed, using alternative method...")
            where_clause = f".eq('user_id', '{user_id}')" if user_id else ""
            
            all_receipts_query = supabase.table("receipts").select("id, user_id, file_hash, uploaded_at, current_status, current_stage, raw_file_url").order("uploaded_at")
            if user_id:
                all_receipts_query = all_receipts_query.eq("user_id", user_id)
            
            all_receipts = all_receipts_query.execute()
            
            # Group by file_hash
            hash_groups = {}
            for receipt in all_receipts.data:
                file_hash = receipt.get('file_hash')
                if file_hash:
                    if file_hash not in hash_groups:
                        hash_groups[file_hash] = []
                    hash_groups[file_hash].append(receipt)
            
            # Find groups with more than 1 receipt
            duplicates = []
            for file_hash, receipts in hash_groups.items():
                if len(receipts) > 1:
                    duplicates.append({
                        'file_hash': file_hash,
                        'count': len(receipts),
                        'receipts': receipts
                    })
            
            # Sort by count descending
            duplicates.sort(key=lambda x: x['count'], reverse=True)
        
        return duplicates
    except Exception as e:
        print(f"âŒ Error finding duplicates: {e}")
        return []


def get_receipt_related_data_count(receipt_id: str) -> Dict[str, int]:
    """è·å–æŸä¸ªå°ç¥¨çš„å…³è”æ•°æ®æ•°é‡"""
    try:
        # Count receipt_items
        items_result = supabase.table("receipt_items").select("id", count="exact").eq("receipt_id", receipt_id).execute()
        items_count = items_result.count if items_result.count else 0
        
        # Count receipt_summaries
        summaries_result = supabase.table("receipt_summaries").select("id", count="exact").eq("receipt_id", receipt_id).execute()
        summaries_count = summaries_result.count if summaries_result.count else 0
        
        # Count receipt_processing_runs
        runs_result = supabase.table("receipt_processing_runs").select("id", count="exact").eq("receipt_id", receipt_id).execute()
        runs_count = runs_result.count if runs_result.count else 0
        
        return {
            'items': items_count,
            'summaries': summaries_count,
            'runs': runs_count
        }
    except Exception as e:
        print(f"âš ï¸  Error getting related data count: {e}")
        return {'items': 0, 'summaries': 0, 'runs': 0}


def delete_receipt_and_related_data(receipt_id: str, dry_run: bool = True) -> bool:
    """
    åˆ é™¤å°ç¥¨åŠæ‰€æœ‰å…³è”æ•°æ®
    
    Args:
        receipt_id: Receipt ID to delete
        dry_run: If True, only print what would be deleted
        
    Returns:
        True if successful (or would be successful in dry_run mode)
    """
    if dry_run:
        print(f"  [DRY RUN] Would delete receipt {receipt_id} and related data")
        return True
    
    try:
        # Delete in correct order (children first due to foreign key constraints)
        # 1. receipt_items
        supabase.table("receipt_items").delete().eq("receipt_id", receipt_id).execute()
        
        # 2. receipt_summaries
        supabase.table("receipt_summaries").delete().eq("receipt_id", receipt_id).execute()
        
        # 3. receipt_processing_runs
        supabase.table("receipt_processing_runs").delete().eq("receipt_id", receipt_id).execute()
        
        # 4. receipts (CASCADE should handle remaining references)
        supabase.table("receipts").delete().eq("id", receipt_id).execute()
        
        print(f"  âœ… Deleted receipt {receipt_id}")
        return True
    except Exception as e:
        print(f"  âŒ Error deleting receipt {receipt_id}: {e}")
        return False


def clean_duplicates(user_id: str = None, dry_run: bool = True):
    """
    æ¸…ç†é‡å¤å°ç¥¨
    
    Args:
        user_id: Optional user_id to filter by
        dry_run: If True, only print what would be deleted without actually deleting
    """
    print("\n" + "="*60)
    print("ğŸ§¹ æ¸…ç†é‡å¤å°ç¥¨")
    print("="*60)
    
    if dry_run:
        print("âš ï¸  DRY RUN MODE - ä¸ä¼šå®é™…åˆ é™¤æ•°æ®")
    else:
        print("âš ï¸  LIVE MODE - å°†å®é™…åˆ é™¤æ•°æ®ï¼")
        response = input("\nç¡®è®¤è¦åˆ é™¤é‡å¤æ•°æ®å—ï¼Ÿè¾“å…¥ 'YES' ç»§ç»­: ")
        if response != "YES":
            print("âŒ æ“ä½œå·²å–æ¶ˆ")
            return
    
    print()
    
    duplicates = find_duplicate_receipts(user_id)
    
    if not duplicates:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„å°ç¥¨ï¼")
        return
    
    print(f"\nğŸ“Š å‘ç° {len(duplicates)} ç»„é‡å¤å°ç¥¨ï¼ˆå…± {sum(d['count'] for d in duplicates)} å¼ å°ç¥¨ï¼‰\n")
    
    total_to_delete = 0
    total_to_keep = 0
    
    for idx, dup_group in enumerate(duplicates, 1):
        file_hash = dup_group['file_hash']
        count = dup_group['count']
        receipts = dup_group['receipts']
        
        print(f"\n{'='*60}")
        print(f"é‡å¤ç»„ #{idx}: {count} å¼ é‡å¤å°ç¥¨")
        print(f"file_hash: {file_hash[:20]}...")
        print(f"{'='*60}")
        
        # ä¿ç•™æœ€æ—©ä¸Šä¼ çš„
        keep_receipt = receipts[0]
        delete_receipts = receipts[1:]
        
        print(f"\nâœ… ä¿ç•™:")
        print(f"  ID: {keep_receipt['id']}")
        print(f"  ä¸Šä¼ æ—¶é—´: {keep_receipt['uploaded_at']}")
        print(f"  çŠ¶æ€: {keep_receipt['current_status']}")
        related = get_receipt_related_data_count(keep_receipt['id'])
        print(f"  å…³è”æ•°æ®: {related['items']} items, {related['summaries']} summaries, {related['runs']} runs")
        total_to_keep += 1
        
        print(f"\nâŒ åˆ é™¤ ({len(delete_receipts)} å¼ ):")
        for receipt in delete_receipts:
            print(f"\n  ID: {receipt['id']}")
            print(f"  ä¸Šä¼ æ—¶é—´: {receipt['uploaded_at']}")
            print(f"  çŠ¶æ€: {receipt['current_status']}")
            related = get_receipt_related_data_count(receipt['id'])
            print(f"  å…³è”æ•°æ®: {related['items']} items, {related['summaries']} summaries, {related['runs']} runs")
            
            success = delete_receipt_and_related_data(receipt['id'], dry_run=dry_run)
            if success:
                total_to_delete += 1
    
    print("\n" + "="*60)
    print("ğŸ“Š æ¸…ç†æ€»ç»“")
    print("="*60)
    print(f"ä¿ç•™å°ç¥¨: {total_to_keep}")
    print(f"{'å°†åˆ é™¤' if dry_run else 'å·²åˆ é™¤'}: {total_to_delete}")
    print()
    
    if dry_run:
        print("ğŸ’¡ è¿™æ˜¯ DRY RUN æ¨¡å¼ï¼Œæ²¡æœ‰å®é™…åˆ é™¤æ•°æ®")
        print("ğŸ’¡ å¦‚æœç¡®è®¤æ— è¯¯ï¼Œè¯·è¿è¡Œ: python clean_duplicate_receipts.py")
    else:
        print("âœ… æ¸…ç†å®Œæˆï¼")


def main():
    parser = argparse.ArgumentParser(description="æ¸…ç†é‡å¤çš„å°ç¥¨æ•°æ®")
    parser.add_argument("--dry-run", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…åˆ é™¤æ•°æ®")
    parser.add_argument("--user-id", type=str, help="åªæ¸…ç†æŒ‡å®šç”¨æˆ·çš„é‡å¤æ•°æ®")
    
    args = parser.parse_args()
    
    # Default to dry-run if not explicitly disabled
    dry_run = args.dry_run if '--dry-run' in sys.argv else (not any(arg in sys.argv for arg in ['--no-dry-run', '--live']))
    
    clean_duplicates(user_id=args.user_id, dry_run=dry_run)


if __name__ == "__main__":
    main()
