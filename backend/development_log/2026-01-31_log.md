# 2026-01-31 工作日志

## 项目：LedgerLens - 收据 OCR 后端系统

### 主要成就
今天完成了数据库 schema 的重大重构、backup LLM 结果保存、调试模式实现、以及 current_stage 的细粒度更新。同时制定了 MVP 上线计划和 API 安全防护方案。最后整理了 database migration 文件，分离了结构变更和数据操作。

---

## 一、数据库 Schema 重构

### 1. 完全重新设计数据库结构
**目标**：从混乱的旧 schema 重构为清晰、可扩展的新结构

**完成内容**：
- ✅ 创建 `001_schema_v2.sql` - 全新的数据库 schema
  - `store_chains`: 商店连锁（如 Costco, T&T）
  - `store_locations`: 商店位置（具体地址）
  - `store_chain_prompts`: RAG prompts 和 extraction rules
  - `users`: 用户表（扩展 auth.users）
  - `receipts`: 收据主表（当前状态）
  - `receipt_processing_runs`: 处理历史（每次尝试的详细记录）
  - `api_calls`: API 调用统计
  - `store_candidates`: 未匹配的商店候选（待审核）

- ✅ 删除所有旧 migration 文件（001-008.sql）
- ✅ 创建新的 migration 文件：
  - `002_insert_initial_data.sql`: 初始数据（商店、prompts）
  - `003_add_file_hash.sql`: 文件哈希（去重）
  - `004_update_user_class.sql`: 用户等级（super_admin, admin, premium, free）
  - `005_delete_old_receipts_without_hash.sql`: 清理旧数据
  - `006_add_validation_status.sql`: 验证状态字段
  - `007_add_chain_name_to_store_locations.sql`: 添加 chain_name 字段和触发器

**设计亮点**：
- **职责分离**：`receipts` 表存储当前状态，`receipt_processing_runs` 存储完整历史
- **可扩展性**：支持 OAuth、Stripe 集成
- **数据完整性**：使用 UUID、外键约束、check constraints

---

### 2. 数据库表设计说明

#### `receipts` 表（主表）
- **作用**：代表一张小票的整体状态（业务实体）
- **特点**：每个小票只有一条记录，存储当前状态
- **用途**：快速查询（哪些需要审核？哪些成功了？）

#### `receipt_processing_runs` 表（历史表）
- **作用**：记录每次处理尝试的详细信息（技术审计表）
- **特点**：每个小票可能有多条记录（一次 OCR + 多次 LLM 尝试）
- **用途**：调试（为什么失败？Gemini 和 GPT 结果对比？）

**为什么需要拆成两个表？**
1. 职责分离：业务视角 vs 技术视角
2. 性能优化：业务查询不需要 JOIN 大表
3. 数据量差异：receipts 1 条，processing_runs 可能 3-5 条
4. 查询场景不同：业务查询用 receipts，技术查询用 processing_runs

---

### 3. current_stage 细粒度更新

**目标**：更细粒度的状态追踪，便于调试

**完成内容**：
- ✅ 创建 `008_update_current_stage.sql` migration
- ✅ 更新 `current_stage` 从 4 个值扩展到 8 个值：
  - 旧值：`'ocr'`, `'llm_primary'`, `'llm_fallback'`, `'manual'`
  - 新值：`'ocr_google'`, `'ocr_aws'`, `'llm_primary'`, `'llm_fallback'`, `'sum_check_failed'`, `'manual_review'`, `'success'`, `'failed'`

- ✅ 更新所有代码中的 `current_stage` 赋值
- ✅ 在关键处理阶段自动更新 `current_stage`

**优势**：
- 快速定位小票卡在哪个阶段
- 例如：`sum_check_failed` 表示 sum check 失败，需要人工审核

---

## 二、Backup LLM 结果保存

### 问题
GPT-4o-mini backup LLM 的处理结果没有被保存到 `receipt_processing_runs` 表，导致无法查看 backup 处理历史。

### 解决方案
- ✅ 在 `_backup_check_with_aws_ocr` 函数中添加 `save_processing_run` 调用
- ✅ GPT backup LLM 处理完成后立即保存（无论 sum check 是否通过）
- ✅ 处理失败时也保存失败记录

**实现位置**：
- `backend/app/core/workflow_processor.py` (Line 698-719)

---

## 三、调试模式实现

### 问题
调试时重复上传同一张收据会被 duplicate check 阻止，删除旧记录又无法对比结果。

### 解决方案
- ✅ 添加 `ALLOW_DUPLICATE_FOR_DEBUG` 环境变量
- ✅ 调试模式下，检测到重复时自动修改 `file_hash`（添加时间戳后缀）
- ✅ 保留所有历史记录，可通过 `receipt_processing_runs` 对比结果

**实现**：
- `backend/app/config.py`: 添加 `allow_duplicate_for_debug` 配置（支持 `field_validator` 解析字符串）
- `backend/app/core/workflow_processor.py`: 在 duplicate check 时应用调试模式逻辑

**使用方法**：
```bash
# 在 .env 文件中
ALLOW_DUPLICATE_FOR_DEBUG=true
```

---

## 四、Store 相关功能

### 1. Store Candidate 导出脚本
- ✅ 创建 `scripts/export_store_candidates.py`
- ✅ 支持 `--simplified` 和 `--formatted` 两种输出格式
- ✅ 格式化规则：title case、zip code、phone number 等

### 2. Store Location 导入脚本
- ✅ 创建 `scripts/import_store_locations.py`
- ✅ 直接从 Excel 导入到 `store_chains` 和 `store_locations` 表
- ✅ 自动创建 chain（如果不存在）
- ✅ 处理 address_line2 的数字类型问题（1190.0 → 1190）

### 3. Store Matching 逻辑优化
- ✅ 实现两阶段匹配（OCR → LLM）
- ✅ 只有两个阶段都失败时才创建 `store_candidate`
- ✅ 支持高置信度匹配（>= 85%）和低置信度建议（50-85%）

---

## 五、代码质量改进

### 1. 错误处理增强
- ✅ 添加 `try...except` 块处理文件 I/O 错误
- ✅ 添加 `None` 检查防止 LLM 结果为空
- ✅ 改进日志消息，包含更多上下文

### 2. 异步编程修复
- ✅ 修复缺失的 `await` 关键字
- ✅ 确保所有异步调用正确使用 `await`

### 3. Receipt ID 唯一性增强
- ✅ 在 receipt ID 中包含微秒的最后两位数字
- ✅ 增强高并发场景下的唯一性

---

## 六、未完成的后端 TODO 列表

### 按重要性和难易度评分

| TODO | 重要性 (1-10) | 难易度 (1-10) | 综合得分 | 优先级 | 预计工作量 |
|------|-------------|-------------|---------|--------|-----------|
| **过滤不是小票的图片** | 9 | 7 | 16 | 🔴 最高 | 5-7天 |
| **验证精确程度** | 9 | 8 | 17 | 🔴 最高 | 持续 |
| **过滤模糊小票** | 8 | 6 | 14 | 🟠 高 | 3-5天 |
| **想办法节约调模型成本** | 8 | 7 | 15 | 🟠 高 | 5-10天 |
| **阻挡重复的照片和重复上传** | 7 | 2 | 9 | 🟡 中 | 1天 |
| **批量处理？错峰发给Gemini** | 6 | 4 | 10 | 🟡 中 | 2-3天 |
| **允许一张照片里有多个小票** | 5 | 9 | 14 | 🟢 低 | 10-15天 |

**评分说明**：
- **重要性 (1-10)**: 对产品核心功能和用户体验的影响
- **难易度 (1-10)**: 实现的技术难度（10 = 最难）
- **综合得分**: 重要性 + 难易度（用于排序）
- **优先级**: 🔴 最高 > 🟠 高 > 🟡 中 > 🟢 低

### 详细说明

#### 1. 过滤模糊小票
- **重要性**: 8/10 - 提高数据质量，减少人工审核
- **难易度**: 6/10 - 需要图像质量评估算法
- **实现思路**:
  - 使用图像清晰度指标（如 Laplacian variance）
  - 设置阈值，低于阈值自动拒绝
  - 在 OCR 之前进行检测，节省成本
- **预计工作量**: 3-5天

#### 2. 过滤不是小票的图片
- **重要性**: 9/10 - 防止误用，节省成本
- **难易度**: 7/10 - 需要图像分类模型
- **实现思路**:
  - 使用轻量级图像分类模型（如 MobileNet）
  - 训练或使用预训练模型识别"收据"类别
  - 在 OCR 之前进行检测
- **预计工作量**: 5-7天（如果使用预训练模型，2-3天）

#### 3. 阻挡重复的照片和重复上传
- **重要性**: 7/10 - 节省成本，避免重复处理
- **难易度**: 2/10 - 已实现 file_hash，只需优化
- **实现思路**:
  - ✅ 已实现：使用 `file_hash` 检测重复
  - 可优化：添加相似图片检测（使用图像哈希如 perceptual hash）
- **预计工作量**: 1天（优化）

#### 4. 验证精确程度
- **重要性**: 9/10 - 核心功能，影响用户体验
- **难易度**: 8/10 - 需要建立验证体系
- **实现思路**:
  - 创建验证数据集（人工标注的 ground truth）
  - 定期运行验证脚本，计算准确率
  - 对比不同 LLM 模型的结果
  - 建立持续改进机制
- **预计工作量**: 持续（初始 5-7天，后续持续）

#### 5. 想办法节约调模型成本
- **重要性**: 8/10 - 直接影响运营成本
- **难易度**: 7/10 - 需要多方面的优化
- **实现思路**:
  - **缓存机制**: 相同商店的收据使用缓存的 prompt
  - **模型选择**: 简单收据用 Gemini Flash，复杂收据用 GPT-4o-mini
  - **批量处理**: 合并多个请求（如果 API 支持）
  - **OCR 优化**: 优先使用免费的 OCR（Google Document AI free tier）
  - **智能重试**: 减少不必要的重试
  - **成本监控**: 添加成本追踪，识别高成本场景
- **预计工作量**: 5-10天

#### 6. 批量处理？错峰发给Gemini
- **重要性**: 6/10 - 提高处理效率
- **难易度**: 4/10 - 已有基础，只需优化
- **实现思路**:
  - ✅ 已实现：Gemini rate limiter（15 requests/minute）
  - 可优化：智能队列，错峰处理
  - 可优化：预测处理时间，提前排队
- **预计工作量**: 2-3天

#### 7. 允许一张照片里有多个小票
- **重要性**: 5/10 - 边缘场景，需求不明确
- **难易度**: 9/10 - 需要图像分割和多个 OCR 处理
- **实现思路**:
  - 使用图像分割模型识别多个收据区域
  - 对每个区域单独进行 OCR 和 LLM 处理
  - 需要处理边界情况（重叠、倾斜等）
- **预计工作量**: 10-15天
- **建议**: MVP 阶段暂不考虑，后续根据用户需求决定

---

## 七、MVP 上线计划

### 阶段 1：安全防护（最高优先级，1-2周）

#### 1.1 API 认证（部分完成 ⚠️）

**当前实现状态**：基础 JWT 认证已实现，但功能不完整

**已实现的功能**：

1. **JWT Token 生成端点** (`/api/auth/authorization`)
   - 接受 `user_id` (Supabase UID)，生成 JWT token
   - 优先尝试使用 Supabase Admin API 生成 session token
   - 如果失败，回退到手动生成 JWT token（使用 `SUPABASE_JWT_SECRET`）
   - Token 过期时间：
     - `super_admin` 用户：7 天
     - 其他用户：1 小时
   - 返回 token 和使用说明（Swagger UI 和 curl 示例）

2. **JWT Token 验证** (`get_current_user` 函数)
   - 使用 FastAPI 的 `HTTPBearer` 自动提取 Bearer token
   - 使用 PyJWT 验证 token 签名和过期时间
   - 从 token payload 的 `sub` 字段提取 `user_id`
   - 禁用 audience 验证（`verify_aud=False`）以支持手动生成的 token
   - 详细的错误处理和调试日志

3. **Swagger UI 集成**
   - 配置 OpenAPI schema，显示 "Authorize" 按钮
   - 自动为受保护的端点添加 security requirement
   - 用户可以在 Swagger UI 中输入 token 进行测试

4. **应用到部分端点**
   - ✅ `/api/receipt/workflow` - 单个收据处理
   - ✅ `/api/receipt/workflow-bulk` - 批量收据处理
   - ✅ RAG 管理 API (`/api/rag/*`) - 需要 admin 权限

**实现位置**：
- `backend/app/services/auth/jwt_auth.py` - JWT 验证逻辑
- `backend/app/main.py` - Token 生成端点和受保护路由

**未实现的功能**：
- ❌ 使用量限制（quota checking）- 需要检查用户每月处理的小票数量
- ❌ Rate limiting - 需要限制每个用户/IP 的请求频率
- ❌ 用户等级验证 - 虽然有 `user_class` 字段，但没有在认证流程中使用
- ❌ Token 刷新机制 - 当前 token 过期后需要重新调用 `/api/auth/authorization`

**下一步实现路径**：

1. **使用量限制**（优先级：高，预计 1-2 天）
   - 在 `users` 表添加 `monthly_quota_used` 字段（或使用 `receipts` 表按月统计）
   - 创建 `check_user_quota(user_id: str)` 函数
   - 在 `process_receipt_workflow` 开始时检查配额
   - 配额规则：
     - `free`: 10 张/月
     - `premium`: 100 张/月
     - `admin`/`super_admin`: 无限制
   - 如果超出配额，返回 429 错误

2. **Rate Limiting**（优先级：高，预计 1 天）
   - 安装 `slowapi` 库：`pip install slowapi`
   - 在 `main.py` 中配置 limiter
   - 应用限制：
     - IP 级别：10 requests/minute（防止 DDoS）
     - 用户级别：根据 `user_class` 设置不同限制
   - 示例：
     ```python
     from slowapi import Limiter
     limiter = Limiter(key_func=get_remote_address)
     
     @app.post("/api/receipt/workflow")
     @limiter.limit("10/minute")
     async def workflow(...):
         ...
     ```

3. **用户等级验证**（优先级：中，预计 0.5 天）
   - 创建 `require_premium` 和 `require_admin` 依赖函数
   - 在需要特定权限的端点使用
   - 示例：
     ```python
     async def require_premium(user_id: str = Depends(get_current_user)):
         user = get_user(user_id)
         if user.user_class not in ['premium', 'admin', 'super_admin']:
             raise HTTPException(403, "Premium subscription required")
         return user_id
     ```

4. **Token 刷新机制**（优先级：低，预计 1-2 天）
   - 创建 `/api/auth/refresh` 端点
   - 接受当前 token，验证后生成新 token
   - 前端可以在 token 即将过期时自动刷新

**测试方法**：
1. 获取 token：
   ```bash
   curl -X POST "http://localhost:8000/api/auth/authorization" \
     -H "Content-Type: application/json" \
     -d '{"user_id": "your-supabase-user-id"}'
   ```
2. 使用 token 调用受保护的端点：
   ```bash
   curl -X POST "http://localhost:8000/api/receipt/workflow" \
     -H "Authorization: Bearer <token>" \
     -F "file=@receipt.jpg"
   ```
3. 在 Swagger UI 中：
   - 点击右上角 "Authorize" 按钮
   - 输入 token（不需要 "Bearer" 前缀）
   - 点击 "Authorize"，然后测试端点

**预计剩余工作量**: 2-3天（使用量限制 + Rate limiting）

#### 1.2 使用量限制（必须）
**目标**：防止单个用户过度使用

**实现**：
- Free 用户：每月 10 张小票
- Premium 用户：每月 100 张
- 在 `users` 表添加 `monthly_quota_used` 字段
- 每次上传前检查配额

**预计工作量**: 1-2天

#### 1.3 Rate Limiting（必须）
**目标**：防止 DDoS 攻击和滥用

**实现**：
- IP 级别限制：10 requests/minute
- 用户级别限制：根据 user_class 设置不同限制
- 使用 `slowapi` 库

**预计工作量**: 1天

#### 1.4 最小前端（1-2天）
**目标**：让用户可以上传和查看结果

**实现**：
- 使用 Supabase Auth UI（React/Vue）
- 上传页面（拖拽上传）
- 简单列表（显示处理状态）
- 使用 Tailwind CSS 快速搭建

**预计工作量**: 2-3天

---

### 阶段 2：MVP 功能完善（2-3周）

#### 2.1 数据库优化
- 完成 `needs_review` 调试
- 优化查询性能（索引）
- 数据清理脚本

**预计工作量**: 3-5天

#### 2.2 价格追踪数据库（结构化数据）
**目标**：为未来的 grocery gas buddy 功能做准备

**实现**：
- 创建 `receipt_items` 表（从 JSONB 提取）
- 创建 `store_prices` 表（store_id, product_name, price, date）
- 定期 ETL 任务从 `receipts.structured_data` 提取价格数据

**预计工作量**: 5-7天

#### 2.3 Dashboard 基础版
**目标**：月度统计和可视化

**实现**：
- 月度统计（总金额、商店分布、类别分布）
- 简单图表（Chart.js 或 Recharts）
- CSV 导出功能

**预计工作量**: 5-7天

---

### 阶段 3：商业化准备（3-4周）

#### 3.1 会员制和收费
**目标**：实现付费功能

**实现**：
- 集成 Stripe
- 订阅管理（升级/降级/取消）
- Webhook 处理订阅状态

**预计工作量**: 7-10天

#### 3.2 完整 Dashboard
**目标**：多维度分析和可视化

**实现**：
- 多维度分析
- 时间范围筛选
- 数据可视化

**预计工作量**: 7-10天

#### 3.3 第三方集成
**目标**：允许用户接入自己的系统

**实现**：
- CSV/JSON 导出 API
- Webhook 支持
- API 文档

**预计工作量**: 5-7天

---

## 八、API 安全防护方案

### 当前风险
- ❌ 所有 API 端点都是公开的
- ❌ 任何人都可以使用你的 API key 处理图片
- ❌ 没有使用量限制
- ❌ 没有认证机制

### 推荐方案：Supabase JWT 认证

#### 实现步骤

**1. 创建认证 Middleware**
```python
from fastapi import Depends, HTTPException, Header
from supabase import create_client
import jwt

async def get_current_user(
    authorization: str = Header(..., alias="Authorization")
) -> str:
    """验证 Supabase JWT token 并返回 user_id"""
    if not authorization.startswith("Bearer "):
        raise HTTPException(401, "Invalid authorization header")
    
    token = authorization.replace("Bearer ", "")
    try:
        # 使用 Supabase 的 JWT secret 验证
        payload = jwt.decode(token, settings.supabase_jwt_secret, algorithms=["HS256"])
        user_id = payload.get("sub")  # Supabase JWT 的 user_id 在 'sub' 字段
        return user_id
    except jwt.InvalidTokenError:
        raise HTTPException(401, "Invalid token")
```

**2. 应用到所有 API 端点**
```python
@app.post("/api/receipt/workflow")
async def workflow(
    file: UploadFile,
    user_id: str = Depends(get_current_user)  # 自动验证
):
    # 使用验证后的 user_id
    ...
```

**3. 添加使用量配额检查**
```python
async def check_quota(user_id: str):
    """检查用户本月使用量"""
    user = get_user(user_id)
    monthly_limit = {
        'free': 10,
        'premium': 100,
        'enterprise': 1000
    }.get(user.user_class, 10)
    
    current_month_count = count_receipts_this_month(user_id)
    if current_month_count >= monthly_limit:
        raise HTTPException(429, f"Monthly quota exceeded ({monthly_limit} receipts)")
```

**4. 添加 Rate Limiting**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/api/receipt/workflow")
@limiter.limit("10/minute")  # 每分钟 10 次
async def workflow(request: Request, file: UploadFile, user_id: str = Depends(get_current_user)):
    ...
```

---

## 九、MVP 上线路径

### 第 1 周：安全防护
1. ✅ 实现 Supabase Auth（1-2天）
2. ✅ 添加使用量限制（1天）
3. ✅ 添加 Rate Limiting（1天）
4. ✅ 测试安全措施（1天）

### 第 2 周：最小前端
1. ✅ 搭建 React/Vue 项目（1天）
2. ✅ 集成 Supabase Auth UI（1天）
3. ✅ 上传页面（2天）
4. ✅ 列表页面（1天）

### 第 3 周：测试和优化
1. ✅ 朋友内测（收集反馈）
2. ✅ 修复 bug
3. ✅ 性能优化

---

## 十、中期计划（3-6个月）

### 1. 数据挖掘和价格追踪
- **目标**：建立价格数据库，为 grocery gas buddy 功能做准备
- **实现**：
  - 从 `receipts.structured_data` 提取价格数据
  - 创建 `store_prices` 表
  - 建立价格趋势分析
  - 支持价格查询 API

### 2. 用户增长功能
- **目标**：提高用户粘性和留存
- **实现**：
  - 完整的 Dashboard（多维度分析）
  - 数据导出（CSV, JSON, Excel）
  - 第三方集成（记账软件、Excel 等）
  - 移动端 App（可选）

### 3. 商业化功能
- **目标**：实现可持续的商业模式
- **实现**：
  - Stripe 集成（订阅管理）
  - 多层级会员制（Free, Premium, Enterprise）
  - 使用量监控和告警
  - 发票和账单系统

### 4. 技术优化
- **目标**：提高处理效率和降低成本
- **实现**：
  - 图像质量检测（过滤模糊图片）
  - 图像分类（过滤非收据图片）
  - 成本优化（缓存、批量处理、模型选择）
  - 性能优化（数据库索引、查询优化）

---

## 十一、从上次 Commit 到现在的未提交更改

### Git 统计
- **上次 Commit**: `16e0f7f` - "before restruturing database"
- **修改文件数**: 20 个文件
- **新增代码**: +1669 行
- **删除代码**: -1306 行
- **净增加**: +363 行

### 数据库相关
- ✅ 创建 `001_schema_v2.sql` - 全新数据库 schema（260 行）
- ✅ 创建 `002_insert_initial_data.sql` - 初始数据
- ✅ 创建 `003_add_file_hash.sql` - 文件哈希
- ✅ 创建 `004_update_user_class.sql` - 用户等级
- ✅ 创建 `005_delete_old_receipts_without_hash.sql` - 清理旧数据
- ✅ 创建 `006_add_validation_status.sql` - 验证状态
- ✅ 创建 `007_add_chain_name_to_store_locations.sql` - chain_name 字段
- ✅ 创建 `008_update_current_stage.sql` - current_stage 更新
- ✅ 删除 8 个旧 migration 文件

### 代码相关
- ✅ 更新 `supabase_client.py` - 适配新 schema（+490 行修改）
  - `create_receipt`, `save_processing_run`, `update_receipt_status`
  - `get_store_chain`, `create_store_candidate`
  - `check_duplicate_by_hash`, `calculate_file_hash`
  - `get_test_user_id` 优化
- ✅ 更新 `workflow_processor.py` - 集成数据库保存（+847 行修改）
  - 保存所有 processing runs（OCR + LLM primary + LLM fallback）
  - 更新 receipt status 和 stage
  - 实现调试模式（允许重复上传）
  - 添加细粒度的 current_stage 更新
- ✅ 更新 `receipt_llm_processor.py` - 使用新 store matching 逻辑（+132 行修改）
  - 两阶段匹配（OCR → LLM）
  - 只在两个阶段都失败时创建 store_candidate
- ✅ 更新 `address_matcher.py` - 改进 store matching（+260 行修改）
  - 返回详细的匹配信息（confidence_score, suggested_chain_id 等）
- ✅ 更新 `sum_checker.py` - 优化 sum check 逻辑（+93 行修改）
  - 处理 deposit 和 fee 的情况
- ✅ 创建 `scripts/export_store_candidates.py` - 导出脚本（385 行）
- ✅ 创建 `scripts/import_store_locations.py` - 导入脚本（348 行）
- ✅ 更新 `config.py` - 添加 `ALLOW_DUPLICATE_FOR_DEBUG`（+27 行修改）
  - 使用 `field_validator` 解析布尔值字符串
- ✅ 更新 `prompt_manager.py` - 改进 prompts（+42 行修改）
- ✅ 更新 `statistics_manager.py` - 适配新 schema（+161 行修改）

### 文档相关
- ✅ 创建 `docs/DATABASE_DESIGN.md` - 数据库设计说明（208 行）
- ✅ 更新 `MIGRATION_NOTES.md` - 迁移说明
- ✅ 创建 `development_log/2026-01-31_log.md` - 本日志

### 删除的文件
- ❌ `database/001_schema_v0.sql` - 旧 schema
- ❌ `database/002_merchant_prompts.sql` - 旧 prompts
- ❌ `database/003_insert_example_prompt.sql` - 旧示例
- ❌ `database/004_add_extraction_rules.sql` - 旧规则
- ❌ `database/005_insert_extraction_rules_examples.sql` - 旧示例
- ❌ `database/006_llm_statistics.sql` - 旧统计表
- ❌ `database/007_merchant_locations.sql` - 旧商家表
- ❌ `database/008_verify_merchant_data.sql` - 旧验证脚本

---

## 十二、下一步行动计划

### 立即执行（本周）
1. **API 安全防护**（最高优先级）
   - 实现 Supabase JWT 认证
   - 添加使用量配额检查
   - 添加 Rate Limiting
   - 预计工作量：3-5天

2. **完成 needs_review 调试**
   - 修复所有已知的 sum check 问题
   - 优化 validation_status 逻辑
   - 预计工作量：2-3天

### 短期（2-4周）
3. **最小前端**
   - 登录/注册页面
   - 上传页面
   - 列表页面
   - 预计工作量：5-7天

4. **图像质量检测**
   - 过滤模糊小票
   - 过滤非收据图片
   - 预计工作量：5-7天

### 中期（1-3个月）
5. **价格追踪数据库**
   - 创建 receipt_items 表
   - 创建 store_prices 表
   - ETL 任务
   - 预计工作量：7-10天

6. **Dashboard 开发**
   - 月度统计
   - 数据可视化
   - 预计工作量：7-10天

7. **成本优化**
   - 缓存机制
   - 批量处理优化
   - 模型选择策略
   - 预计工作量：5-10天

---

## 十三、技术债务清单

### 高优先级
1. ❌ API 认证缺失（安全风险）
2. ❌ 使用量限制缺失（成本风险）
3. ❌ Rate Limiting 缺失（DDoS 风险）
4. ⚠️ 图像质量检测缺失（数据质量）
5. ⚠️ 非收据图片过滤缺失（成本浪费）

### 中优先级
6. ⚠️ 成本优化（缓存、批量处理）
7. ⚠️ 验证精确程度（建立验证体系）
8. ⚠️ 数据库查询优化（索引、查询优化）

### 低优先级
9. ⚠️ 多收据图片支持（需求不明确）
10. ⚠️ 相似图片检测（已有 file_hash）

---

## 十四、数据库 Migration 文件整理

### 问题
数据库 migration 文件夹中混合了结构变更 SQL 和数据插入 SQL，导致：
- 难以区分哪些是结构变更，哪些是数据操作
- 数据插入操作应该通过 API 或脚本完成，而不是 SQL migration
- 未来如果需要让 LLM 重新生成数据，需要清晰的描述

### 解决方案
- ✅ 创建 `2026-01-31_MIGRATION_NOTES.md`，详细描述所有数据插入操作
- ✅ 删除纯数据插入的 migration 文件：
  - `002_insert_initial_data.sql` - 初始商店数据
  - `010_enhance_deposit_fee_rag.sql` - RAG 数据增强
  - `005_delete_old_receipts_without_hash.sql` - 数据清理操作
- ✅ 从 `009_tag_based_rag_system.sql` 中移除所有数据插入部分，只保留表结构创建
- ✅ 从 `006_add_validation_status.sql`、`007_add_chain_name_to_store_locations.sql`、`008_update_current_stage.sql` 中移除数据回填部分，只保留结构变更
- ✅ 所有数据操作描述已记录到 `2026-01-31_MIGRATION_NOTES.md`，包含：
  - 详细的 SQL 模板
  - 字段说明和示例
  - 验证查询
  - 初始化方法（API 或脚本）

### 最终 Migration 文件列表
现在 `backend/database/` 文件夹中只包含结构变更的 SQL 文件：
- `001_schema_v2.sql` - 基础 schema
- `003_add_file_hash.sql` - 添加 file_hash 字段
- `004_update_user_class.sql` - 更新 user_class 约束
- `006_add_validation_status.sql` - 添加 validation_status 字段
- `007_add_chain_name_to_store_locations.sql` - 添加 chain_name 字段和触发器
- `008_update_current_stage.sql` - 更新 current_stage 约束
- `009_tag_based_rag_system.sql` - 创建 tag-based RAG 表结构

所有数据插入操作应通过：
- RAG 管理 API (`/api/rag/*`)
- 初始化脚本 (`backend/scripts/init_deposit_fee_rag.py`)
- 或参考 `2026-01-31_MIGRATION_NOTES.md` 中的描述

---

## 十五、总结

### 今天完成的工作
1. **数据库重构**：完全重新设计 schema，支持扩展和 OAuth/Stripe
2. **Backup LLM 保存**：修复 backup 结果未保存的问题
3. **调试模式**：实现允许重复上传的调试功能
4. **current_stage 细化**：从 4 个值扩展到 8 个值，便于调试
5. **Store 管理**：导入/导出脚本，地址类型修复
6. **MVP 计划**：制定详细的上线计划和安全防护方案
7. **Migration 文件整理**：分离结构变更和数据操作，创建详细的 migration notes

### 项目进度
- **后端核心功能**: 85% ✅
- **数据库设计**: 90% ✅
- **API 认证**: 40% ⚠️（基础完成：JWT token 生成和验证已实现，Swagger UI 集成完成，但使用量限制和 rate limiting 未完成）
- **前端**: 0% ❌
- **商业化功能**: 20% ⚠️
- **RAG 索引系统**: 0% ❌（**需要完全重构** - 见下方说明）

### ⚠️ 重要技术债务：RAG 索引系统需要完全重构

**当前问题**：
- RAG 系统实现混乱，缺乏清晰的架构设计
- Tag 匹配逻辑分散在多个地方
- 没有统一的索引和检索机制
- 缺乏性能优化和缓存策略
- 数据插入方式不统一（SQL migration vs API vs 脚本）

**重构需求**：
1. **系统架构设计**：从系统角度重新思考 RAG 的索引、匹配、检索流程
2. **统一数据管理**：所有 RAG 内容应通过统一的 API 管理，而不是 SQL migration
3. **性能优化**：实现缓存机制，避免每次处理都查询数据库
4. **索引机制**：设计高效的 tag 匹配索引，支持快速检索
5. **可扩展性**：支持动态添加新的 tag 类型和匹配规则
6. **监控和调试**：添加 RAG 使用统计和调试工具

**建议**：在继续添加新功能之前，先完成 RAG 系统的重构，否则技术债务会越来越重。

### 下一步重点
1. **API 安全防护**（必须立即实现 - 使用量限制和 rate limiting，预计 2-3 天）
2. **RAG 系统重构**（最高优先级 - 技术债务，但可以先完成安全防护）
3. **最小前端**（让用户可以试用）
4. **图像质量检测**（提高数据质量）
5. **成本优化**（降低运营成本）

---

*日志生成时间：2026-01-31*
*最后更新：2026-01-31（Migration 文件整理）*
